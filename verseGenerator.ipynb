{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# req = requests.get('https://raw.githubusercontent.com/cyrilou242/RapLyrics-Back/master/datasets/rapus_generalist_lowered.txt')\n",
    "\n",
    "# with open('lyrics/vindicator.txt', 'w') as f:\n",
    "#     f.write(req.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 2706 words\n",
      "1045 unique words\n",
      "['Look', 'I', 'was', 'gonna', 'go', 'easy', 'on', 'you', 'not', 'to', 'hurt', 'your', 'feelings', 'But', 'Im', 'only', 'going', 'to', 'get', 'this', 'one', 'chance', 'Six', 'minutes', 'six', 'minutes', 'Somethings', 'wrong', 'I', 'can', 'feel', 'it', 'Six', 'minutes', 'six', 'minutes', 'Slim', 'Shady', 'youre', 'on', 'Just', 'a', 'feeling', 'Ive', 'got', 'Like', 'somethings', 'about', 'to', 'happen', 'But', 'I', 'dont', 'know', 'what', 'If', 'that', 'means', 'what', 'I', 'think', 'it', 'means', 'were', 'in', 'trouble', 'Big', 'trouble', 'And', 'if', 'he', 'is', 'as', 'bananas', 'as', 'you', 'say', 'Im', 'not', 'taking', 'any', 'chances', 'You', 'are', 'just', 'what', 'the', 'doc', 'ordered', 'Im', 'beginning', 'to', 'feel', 'like', 'a', 'Rap', 'God', 'Rap', 'God', 'All', 'my', 'people', 'from', 'the', 'front', 'to', 'the', 'back', 'nod', 'back', 'nod', 'Now', 'who', 'thinks', 'their', 'arms', 'are', 'long', 'enough', 'to', 'slap', 'box', 'slap', 'box', 'They', 'said', 'I', 'rap', 'like', 'a', 'robot', 'so', 'call', 'me', 'rapbot', 'But', 'for', 'me', 'to', 'rap', 'like', 'a', 'computer', 'must', 'be', 'in', 'my', 'genes', 'I', 'got', 'a', 'laptop', 'in', 'my', 'back', 'pocket', 'My', 'penll', 'go', 'off', 'when', 'I', 'halfcock', 'it', 'Got', 'a', 'fat', 'knot', 'from', 'that', 'rap', 'profit', 'Made', 'a', 'living', 'and', 'a', 'killing', 'off', 'it', 'Ever', 'since', 'Bill', 'Clinton', 'was', 'still', 'in', 'office', 'With', 'Monica', 'Lewinsky', 'feeling', 'on', 'his', 'nutsack', 'Im', 'an', 'MC', 'still', 'as', 'honest', 'But', 'as', 'rude', 'and', 'as', 'indecent', 'as', 'all', 'hell', 'Syllables', 'skillaholic', 'Kill', 'em', 'all', 'with', 'This', 'flippity', 'dippityhippity', 'hiphop', 'You', 'dont', 'really', 'wanna', 'get', 'into', 'a', 'pissing', 'match', 'With', 'this', 'rappity', 'brat', 'Packing', 'a', 'MAC', 'in', 'the', 'back', 'of', 'the', 'Ac', 'Backpack', 'rap', 'crap', 'yapyap', 'yacketyyack', 'And', 'at', 'the', 'exact', 'same', 'time', 'I', 'attempt', 'these', 'lyrical', 'acrobat', 'stunts', 'while', 'Im', 'practicing', 'that', 'Ill', 'still', 'be', 'able', 'to', 'break', 'a', 'motherfuckin', 'table', 'Over', 'the', 'back', 'of', 'a', 'couple', 'of', 'faggots', 'and', 'crack', 'it', 'in', 'half', 'Only', 'realized', 'it', 'was', 'ironic', 'I', 'was', 'signed', 'to', 'Aftermath', 'after', 'the', 'fact', 'How', 'could', 'I', 'not', 'blow', 'All', 'I', 'do', 'is', 'drop', 'F', 'bombs', 'Feel', 'my', 'wrath', 'of', 'attack', 'Rappers', 'are', 'having', 'a', 'rough', 'time', 'period', 'Heres', 'a', 'maxi', 'pad', 'Its', 'actually', 'disastrously', 'bad', 'For', 'the', 'wack', 'while', 'Im', 'masterfully', 'constructing', 'this', 'masterpiece', 'yeah', 'Cause', 'Im', 'beginning', 'to', 'feel', 'like', 'a', 'Rap', 'God', 'Rap', 'God', 'All', 'my', 'people', 'from', 'the', 'front', 'to', 'the', 'back', 'nod', 'back', 'nod', 'Now', 'who', 'thinks', 'their', 'arms', 'are', 'long', 'enough', 'to', 'slap', 'box', 'slap', 'box', 'Let', 'me', 'show', 'you', 'maintaining', 'this', 'shit', 'aint', 'that', 'hard', 'that', 'hard', 'Everybody', 'want', 'the', 'key', 'and', 'the', 'secret', 'to', 'rap', 'Immortality', 'like', 'I', 'have', 'got', 'Well', 'to', 'be', 'truthful', 'the', 'blueprints', 'Simply', 'rage', 'and', 'youthful', 'exuberance', 'Everybody', 'loves', 'to', 'root', 'for', 'a', 'nuisance', 'Hit', 'the', 'Earth', 'like', 'an', 'asteroid', 'Did', 'nothing', 'but', 'shoot', 'for', 'the', 'moon', 'since', 'pew', 'MCs', 'get', 'taken', 'to', 'school', 'with', 'this', 'music', 'Cause', 'I', 'use', 'it', 'as', 'a', 'vehicle', 'to', 'bust', 'a', 'rhyme', 'Now', 'I', 'lead', 'a', 'new', 'school', 'full', 'of', 'students', 'Me', 'Im', 'a', 'product', 'of', 'Rakim', 'Lakim', 'Shabazz', '2Pac', 'NWA', 'Cube', 'hey', 'Doc', 'Ren', 'Yella', 'Eazy', 'thank', 'you', 'they', 'got', 'Slim', 'Inspired', 'enough', 'to', 'one', 'day', 'grow', 'up', 'Blow', 'up', 'and', 'be', 'in', 'a', 'position', 'To', 'meet', 'RunDMC', 'and', 'induct', 'them', 'Into', 'the', 'motherfuckin', 'Rock', 'n', 'Roll', 'Hall', 'of', 'Fame', 'even', 'though', 'I', 'walk', 'in', 'the', 'church', 'And', 'burst', 'in', 'a', 'ball', 'of', 'flames', 'Only', 'Hall', 'of', 'Fame', 'Ill', 'be', 'inducted', 'in', 'is', 'the', 'alcohol', 'of', 'fame', 'On', 'the', 'wall', 'of', 'shame', 'You', 'fags', 'think', 'its', 'all', 'a', 'game', 'Til', 'I', 'walk', 'a', 'flock', 'of', 'flames', 'Off', 'a', 'plank', 'and', 'Tell', 'me', 'what', 'in', 'the', 'fuck', 'are', 'you', 'thinking', 'Little', 'gaylooking', 'boy', 'So', 'gay', 'I', 'can', 'barely', 'say', 'it', 'with', 'a', 'straight', 'face', 'looking', 'boy', 'Youre', 'witnessing', 'a', 'massoccur', 'like', 'youre', 'watching', 'a', 'church', 'gathering', 'take', 'place', 'looking', 'boy', 'Oy', 'vey', 'that', 'boys', 'gay', 'Thats', 'all', 'they', 'say', 'looking', 'boy', 'You', 'get', 'a', 'thumbs', 'up', 'pat', 'on', 'the', 'back', 'And', 'a', 'way', 'to', 'go', 'from', 'your', 'label', 'every', 'day', 'looking', 'boy', 'Hey', 'looking', 'boy', 'what', 'dyou', 'say', 'looking', 'boy', 'I', 'get', 'a', 'hell', 'yeah', 'from', 'Dre', 'looking', 'boy', 'Imma', 'work', 'for', 'everything', 'I', 'have', 'Never', 'asked', 'nobody', 'for', 'shit', 'Get', 'outta', 'my', 'face', 'looking', 'boy', 'Basically', 'boy', 'youre', 'never', 'gonna', 'be', 'capable', 'Of', 'keeping', 'up', 'with', 'the', 'same', 'pace', 'looking', 'boy', 'cause', 'Im', 'beginning', 'to', 'feel', 'like', 'a', 'Rap', 'God', 'Rap', 'God', 'All', 'my', 'people', 'from', 'the', 'front', 'to', 'the', 'back', 'nod', 'back', 'nod', 'The', 'way', 'Im', 'racing', 'around', 'the', 'track', 'call', 'me', 'NASCAR', 'NASCAR', 'Dale', 'Earnhardt', 'of', 'the', 'trailer', 'park', 'the', 'White', 'Trash', 'God', 'Kneel', 'before', 'General', 'Zod', 'this', 'planets', 'Krypton', 'no', 'Asgard', 'Asgard', 'So', 'youll', 'be', 'Thor', 'and', 'Ill', 'be', 'Odin', 'Youre', 'rodent', 'Im', 'omnipotent', 'Let', 'off', 'then', 'Im', 'reloading', 'Immediately', 'with', 'these', 'bombs', 'Im', 'totin', 'And', 'I', 'should', 'not', 'be', 'woken', 'Im', 'the', 'walking', 'dead', 'But', 'Im', 'just', 'a', 'talking', 'head', 'a', 'zombie', 'floating', 'But', 'I', 'got', 'your', 'mom', 'deepthroating', 'Im', 'out', 'my', 'Ramen', 'Noodle', 'We', 'have', 'nothing', 'in', 'common', 'poodle', 'Im', 'a', 'Doberman', 'pinch', 'yourself', 'In', 'the', 'arm', 'and', 'pay', 'homage', 'pupil', 'Its', 'me', 'My', 'honestys', 'brutal', 'But', 'its', 'honestly', 'futile', 'if', 'I', 'dont', 'utilize', 'What', 'I', 'do', 'though', 'for', 'good', 'At', 'least', 'once', 'in', 'a', 'while', 'so', 'I', 'wanna', 'make', 'sure', 'Somewhere', 'in', 'this', 'chicken', 'scratch', 'I', 'scribble', 'and', 'doodle', 'Enough', 'rhymes', 'to', 'Maybe', 'try', 'to', 'help', 'get', 'some', 'people', 'through', 'tough', 'times', 'But', 'I', 'gotta', 'keep', 'a', 'few', 'punchlines', 'Just', 'in', 'case', 'cause', 'even', 'you', 'unsigned', 'Rappers', 'are', 'hungry', 'looking', 'at', 'me', 'like', 'its', 'lunchtime', 'I', 'know', 'there', 'was', 'a', 'time', 'where', 'once', 'I', 'Was', 'king', 'of', 'the', 'underground', 'But', 'I', 'still', 'rap', 'like', 'Im', 'on', 'my', 'Pharoahe', 'Monch', 'grind', 'So', 'I', 'crunch', 'rhymes', 'But', 'sometimes', 'when', 'you', 'combine', 'Appeal', 'with', 'the', 'skin', 'color', 'of', 'mine', 'You', 'get', 'too', 'big', 'and', 'here', 'they', 'come', 'trying', 'to', 'Censor', 'you', 'like', 'that', 'one', 'line', 'I', 'said', 'On', 'Im', 'Back', 'from', 'The', 'Mathers', 'LP', 'One', 'when', 'I', 'tried', 'to', 'say', 'Ill', 'take', 'seven', 'kids', 'from', 'Columbine', 'Put', 'em', 'all', 'in', 'a', 'line', 'Add', 'an', 'AK47', 'a', 'revolver', 'and', 'a', 'nine', 'See', 'if', 'I', 'get', 'away', 'with', 'it', 'now', 'That', 'I', 'aint', 'as', 'big', 'as', 'I', 'was', 'but', 'Im', 'Morphin', 'into', 'an', 'immortal', 'coming', 'through', 'the', 'portal', 'Youre', 'stuck', 'in', 'a', 'time', 'warp', 'from', 'two', 'thousand', 'four', 'though', 'And', 'I', 'dont', 'know', 'what', 'the', 'fuck', 'that', 'you', 'rhyme', 'for', 'Youre', 'pointless', 'as', 'Rapunzel', 'With', 'fucking', 'cornrows', 'You', 'write', 'normal', 'Fuck', 'being', 'normal', 'And', 'I', 'just', 'bought', 'a', 'new', 'ray', 'gun', 'from', 'the', 'future', 'Just', 'to', 'come', 'and', 'shoot', 'ya', 'Like', 'when', 'Fabolous', 'made', 'Ray', 'J', 'mad', 'Cause', 'Fab', 'said', 'he', 'looked', 'like', 'a', 'fag', 'At', 'Mayweathers', 'pad', 'singin', 'to', 'a', 'man', 'While', 'he', 'played', 'piano', 'Man', 'oh', 'man', 'that', 'was', 'a', '247', 'special', 'On', 'the', 'cable', 'channel', 'So', 'Ray', 'J', 'went', 'straight', 'to', 'the', 'radio', 'station', 'the', 'very', 'next', 'day', 'Hey', 'Fab', 'Imma', 'kill', 'you', 'Lyrics', 'coming', 'at', 'you', 'with', 'supersonic', 'speed', 'JJ', 'Fad', 'Uh', 'summa', 'lumma', 'dooma', 'lumma', 'you', 'assuming', 'Im', 'a', 'human', 'What', 'I', 'gotta', 'do', 'to', 'get', 'it', 'through', 'to', 'you', 'Im', 'superhuman', 'Innovative', 'and', 'Im', 'made', 'of', 'rubber', 'so', 'that', 'anything', 'you', 'say', 'is', 'Ricocheting', 'off', 'of', 'me', 'and', 'itll', 'glue', 'to', 'you', 'Im', 'devastating', 'more', 'than', 'ever', 'demonstrating', 'How', 'to', 'give', 'a', 'motherfuckin', 'audience', 'a', 'feeling', 'like', 'its', 'levitating', 'Never', 'fading', 'and', 'I', 'know', 'that', 'haters', 'are', 'forever', 'waiting', 'For', 'the', 'day', 'that', 'they', 'can', 'say', 'I', 'fell', 'off', 'theyll', 'be', 'celebrating', 'Cause', 'I', 'know', 'the', 'way', 'to', 'get', 'em', 'motivated', 'I', 'make', 'elevating', 'music', 'You', 'make', 'elevator', 'music', 'Oh', 'hes', 'too', 'mainstream', 'Well', 'thats', 'what', 'they', 'do', 'When', 'they', 'get', 'jealous', 'they', 'confuse', 'it', 'Its', 'not', 'hiphop', 'its', 'pop', 'Cause', 'I', 'found', 'a', 'hella', 'way', 'to', 'fuse', 'it', 'With', 'rock', 'shock', 'rap', 'with', 'Doc', 'Throw', 'on', 'Lose', 'Yourself', 'and', 'make', 'em', 'lose', 'it', 'I', 'dont', 'know', 'how', 'to', 'make', 'songs', 'like', 'that', 'I', 'dont', 'know', 'what', 'words', 'to', 'use', 'Let', 'me', 'know', 'when', 'it', 'occurs', 'to', 'you', 'While', 'Im', 'ripping', 'any', 'one', 'of', 'these', 'verses', 'that', 'versus', 'you', 'Its', 'curtains', 'Im', 'inadvertently', 'hurtin', 'you', 'How', 'many', 'verses', 'I', 'gotta', 'murder', 'to', 'Prove', 'that', 'if', 'you', 'were', 'half', 'as', 'nice', 'Your', 'songs', 'you', 'could', 'sacrifice', 'virgins', 'to', 'Unghh', 'school', 'flunky', 'pill', 'junky', 'But', 'look', 'at', 'the', 'accolades', 'these', 'skills', 'brung', 'me', 'Full', 'of', 'myself', 'but', 'still', 'hungry', 'I', 'bully', 'myself', 'cause', 'I', 'make', 'me', 'do', 'what', 'I', 'put', 'my', 'mind', 'to', 'When', 'Im', 'a', 'million', 'leagues', 'above', 'you', 'Ill', 'when', 'I', 'speak', 'in', 'tongues', 'But', 'its', 'still', 'tongueincheek', 'fuck', 'you', 'Im', 'drunk', 'So', 'Satan', 'take', 'the', 'fucking', 'wheel', 'Im', 'asleep', 'in', 'the', 'front', 'seat', 'Bumping', 'Heavy', 'D', 'and', 'the', 'Boyz', 'Still', 'Chunky', 'but', 'Funky', 'But', 'in', 'my', 'head', 'theres', 'something', 'I', 'can', 'feel', 'tugging', 'and', 'struggling', 'Angels', 'fight', 'with', 'devils', 'and', 'Heres', 'what', 'they', 'want', 'from', 'me', 'Theyre', 'asking', 'me', 'to', 'eliminate', 'some', 'of', 'the', 'women', 'hate', 'But', 'if', 'you', 'take', 'into', 'consideration', 'the', 'bitter', 'hatred', 'I', 'had', 'Then', 'you', 'may', 'be', 'a', 'little', 'patient', 'and', 'more', 'sympathetic', 'to', 'the', 'situation', 'And', 'understand', 'the', 'discrimination', 'But', 'fuck', 'it', 'Lifes', 'handing', 'you', 'lemons', 'Make', 'lemonade', 'then', 'But', 'if', 'I', 'cant', 'batter', 'the', 'women', 'How', 'the', 'fuck', 'am', 'I', 'supposed', 'to', 'bake', 'them', 'a', 'cake', 'then', 'Dont', 'mistake', 'him', 'for', 'Satan', 'Its', 'a', 'fatal', 'mistake', 'if', 'you', 'think', 'I', 'need', 'to', 'be', 'overseas', 'And', 'take', 'a', 'vacation', 'to', 'trip', 'a', 'broad', 'And', 'make', 'her', 'fall', 'on', 'her', 'face', 'and', 'Dont', 'be', 'a', 'retard', 'be', 'a', 'king', 'Think', 'not', 'Why', 'be', 'a', 'king', 'when', 'you', 'can', 'be', 'a', 'GodAw', 'yeah', 'Its', 'like', 'this', 'like', 'this', 'its', 'Eminem', 'baby', 'back', 'up', 'in', 'that', 'motherfucking', 'ass', 'Till', 'forever', 'till', 'forever', 'One', 'time', 'for', 'your', 'motherfucking', 'mind', 'we', 'represent', 'the', '313', 'You', 'know', 'what', 'Im', 'saying', 'yo', 'they', 'dont', 'know', 'shit', 'about', 'this', 'For', 'the', '96', 'Ayo', 'my', 'pen', 'and', 'paper', 'cause', 'a', 'chain', 'reaction', 'To', 'get', 'your', 'brain', 'relaxing', 'the', 'zanyacting', 'maniac', 'in', 'action', 'A', 'brainiac', 'in', 'fact', 'son', 'you', 'mainly', 'lack', 'attraction', 'You', 'look', 'insanely', 'wack', 'when', 'just', 'a', 'fraction', 'of', 'my', 'tracks', 'run', 'My', 'rhyming', 'skills', 'got', 'you', 'climbing', 'hills', 'I', 'travel', 'through', 'your', 'mind', 'into', 'your', 'spine', 'like', 'siren', 'drills', 'Im', 'sliming', 'grills', 'of', 'roaches', 'with', 'spray', 'that', 'disinfects', 'and', 'twist', 'the', 'necks', 'of', 'rappers', 'til', 'their', 'spinal', 'column', 'disconnects', 'Put', 'this', 'in', 'decks', 'and', 'check', 'the', 'monologue', 'turn', 'your', 'system', 'up', 'Twist', 'them', 'up', 'and', 'indulge', 'in', 'the', 'marijuana', 'smoke', 'This', 'is', 'the', 'season', 'for', 'noise', 'pollution', 'contamination', 'Examination', 'of', 'more', 'car', 'tunes', 'than', 'animation', 'My', 'lamination', 'of', 'narration', 'Hits', 'a', 'snare', 'and', 'bass', 'in', 'a', 'track', 'for', 'duck', 'rapper', 'interrogation', 'When', 'I', 'declare', 'invasion', 'there', 'aint', 'no', 'time', 'to', 'be', 'staring', 'gazing', 'I', 'turn', 'the', 'stage', 'into', 'a', 'barren', 'wasteland', 'Im', 'infinite', 'You', 'heard', 'of', 'hell', 'well', 'I', 'was', 'sent', 'from', 'it', 'I', 'went', 'to', 'it', 'serving', 'a', 'sentence', 'for', 'murderin', 'instruments', 'Now', 'Im', 'trying', 'to', 'repent', 'from', 'it', 'But', 'when', 'I', 'hear', 'the', 'beat', 'Im', 'tempted', 'to', 'make', 'another', 'attempt', 'at', 'it', 'Im', 'infinite', 'Bust', 'it', 'I', 'let', 'the', 'beat', 'commence', 'so', 'I', 'can', 'beat', 'the', 'sense', 'in', 'your', 'elite', 'defense', 'I', 'got', 'some', 'meat', 'to', 'mince', 'a', 'crew', 'to', 'stomp', 'and', 'then', 'two', 'feet', 'to', 'rinse', 'I', 'greet', 'the', 'gents', 'and', 'ladies', 'I', 'spoil', 'loyal', 'fans', 'I', 'foil', 'plans', 'and', 'leave', 'fluids', 'leaking', 'like', 'oil', 'pans', 'My', 'coiled', 'hands', 'around', 'this', 'microphone', 'are', 'lethal', 'One', 'thought', 'in', 'my', 'cerebral', 'is', 'deeper', 'than', 'a', 'Jeep', 'full', 'of', 'people', 'MCs', 'are', 'feeble', 'I', 'came', 'to', 'cause', 'some', 'pandemonium', 'Battle', 'a', 'band', 'of', 'phony', 'MCs', 'and', 'stand', 'the', 'lonely', 'one', 'Imitator', 'intimidator', 'stimulator', 'simulator', 'of', 'data', 'eliminator', 'Theres', 'never', 'been', 'a', 'greater', 'since', 'the', 'burial', 'of', 'Jesus', 'Fuck', 'around', 'and', 'catch', 'all', 'the', 'venereal', 'diseases', 'My', 'thesis', 'will', 'smash', 'a', 'stereo', 'to', 'pieces', 'My', 'a', 'cappella', 'releases', 'classic', 'masterpieces', 'through', 'telekinesis', 'That', 'eases', 'you', 'mentally', 'gently', 'sentimentally', 'instrumentally', 'With', 'entity', 'dementedly', 'meant', 'to', 'be', 'infinite', 'You', 'heard', 'of', 'hell', 'well', 'I', 'was', 'sent', 'from', 'it', 'I', 'went', 'to', 'it', 'serving', 'a', 'sentence', 'for', 'murderin', 'instruments', 'Now', 'Im', 'trying', 'to', 'repent', 'from', 'it', 'But', 'when', 'I', 'hear', 'the', 'beat', 'Im', 'tempted', 'to', 'make', 'another', 'attempt', 'at', 'it', 'Im', 'infinite', 'Man', 'I', 'got', 'evidence', 'Im', 'never', 'dense', 'and', 'I', 'been', 'clever', 'ever', 'since', 'My', 'residence', 'was', 'hesitant', 'to', 'do', 'some', 'shit', 'that', 'represents', 'the', 'MO', 'So', 'Im', 'assuming', 'all', 'responsibility', 'Cause', 'theres', 'a', 'monster', 'will', 'in', 'me', 'that', 'always', 'wants', 'to', 'kill', 'MCs', 'Mic', 'nestler', 'slamming', 'like', 'a', 'wrestler', 'Here', 'to', 'make', 'a', 'mess', 'of', 'a', 'lyric', 'smuggling', 'embezzler', 'No', 'one', 'is', 'specialer', 'my', 'skill', 'is', 'intergalactical', 'I', 'get', 'cynical', 'act', 'a', 'fool', 'then', 'I', 'send', 'a', 'crew', 'back', 'to', 'school', 'I', 'never', 'packed', 'a', 'tool', 'or', 'acted', 'cool', 'it', 'wasnt', 'practical', 'Id', 'rather', 'let', 'a', 'tactical', 'tactful', 'track', 'tickle', 'your', 'fancy', 'In', 'fact', 'I', 'cant', 'see', 'or', 'cant', 'imagine', 'A', 'man', 'who', 'aint', 'a', 'lover', 'of', 'beats', 'or', 'a', 'fan', 'of', 'scratching', 'So', 'this', 'is', 'for', 'my', 'family', 'the', 'kid', 'who', 'had', 'a', 'cameo', 'on', 'my', 'last', 'jam', 'Plus', 'the', 'man', 'who', 'never', 'had', 'a', 'plan', 'B', 'Be', 'all', 'you', 'can', 'be', 'cause', 'once', 'you', 'make', 'an', 'instant', 'hit', 'Im', 'tensed', 'a', 'bit', 'and', 'tempted', 'when', 'I', 'see', 'the', 'sins', 'my', 'friends', 'commit', 'Im', 'infinite', 'You', 'heard', 'of', 'hell', 'well', 'I', 'was', 'sent', 'from', 'it', 'I', 'went', 'to', 'it', 'serving', 'a', 'sentence', 'for', 'murderin', 'instruments', 'Now', 'Im', 'trying', 'to', 'repent', 'from', 'it', 'But', 'when', 'I', 'hear', 'the', 'beat', 'Im', 'tempted', 'to', 'make', 'another', 'attempt', 'at', 'it', 'Im', 'infinite', 'You', 'heard', 'of', 'hell', 'well', 'I', 'was', 'sent', 'from', 'it', 'I', 'went', 'to', 'it', 'serving', 'a', 'sentence', 'for', 'murderin', 'instruments', 'Now', 'Im', 'trying', 'to', 'repent', 'from', 'it', 'But', 'when', 'I', 'hear', 'the', 'beat', 'Im', 'tempted', 'to', 'make', 'another', 'attempt', 'at', 'it', 'Im', 'infinite', '95', '96', '96', 'And', 'on', 'and', 'on', 'and', 'on', 'and', 'on', 'and', 'onYeah', 'Ha', 'ha', 'you', 'feel', 'that', 'baby', 'Yeah', 'I', 'feel', 'it', 'too', 'Damn', 'You', 'know', 'Im', 'so', 'glad', 'we', 'could', 'spend', 'this', 'time', 'together', 'See', 'Im', 'not', 'as', 'crazy', 'as', 'you', 'thought', 'I', 'was', 'am', 'I', 'Heh', 'Im', 'the', 'American', 'dream', 'Im', 'the', 'definition', 'of', 'white', 'trash', 'balling', 'Im', 'right', 'back', 'on', 'em', 'with', 'the', 'I', 'cant', 'call', 'it', 'Same', 'shit', 'different', 'toilet', 'oh', 'you', 'got', 'a', 'nice', 'ass', 'darlin', 'Cant', 'wait', 'to', 'get', 'you', 'into', 'my', 'Benz', 'take', 'you', 'for', 'a', 'spin', 'What', 'you', 'mean', 'we', 'aint', 'fuckin', 'you', 'take', 'me', 'for', 'a', 'friend', 'Let', 'me', 'tell', 'you', 'the', 'whole', 'story', 'of', 'Shadys', 'origin', 'Youll', 'be', 'sorry', 'if', 'you', 'slam', 'my', 'Mercedes', 'door', 'again', 'Now', 'it', 'all', 'started', 'with', 'my', 'father', 'I', 'must', 'have', 'got', 'my', 'pimping', 'genes', 'from', 'him', 'the', 'way', 'he', 'left', 'my', 'mama', 'Im', 'a', 'rolling', 'stone', 'just', 'like', 'him', 'word', 'to', 'Johnny', 'Drama', 'Keep', 'my', 'entourage', 'with', 'me', 'baby', 'Ill', 'make', 'a', 'promise', 'There', 'aint', 'nobody', 'as', 'bomb', 'as', 'me', 'Im', 'as', 'calm', 'as', 'the', 'breeze', 'Im', 'the', 'bees', 'knees', 'his', 'legs', 'and', 'his', 'arms', 'Im', 'a', 'Ssuperstar', 'girl', 'Im', 'ready', 'for', 'you', 'mama', 'Why', 'you', 'think', 'the', 'only', 'thing', 'I', 'got', 'on', 'is', 'my', 'pyjamas', 'Yo', 'I', 'listen', 'to', 'your', 'demo', 'tape', 'and', 'act', 'like', 'I', 'dont', 'like', 'it', 'Aww', 'that', 'shit', 'is', 'wack', 'Six', 'months', 'later', 'you', 'hear', 'your', 'lyrics', 'on', 'my', 'shit', 'What', 'Thats', 'my', 'shit', 'People', 'dont', 'buy', 'shit', 'no', 'more', 'they', 'just', 'dub', 'it', 'Thats', 'why', 'Im', 'still', 'broke', 'and', 'had', 'the', 'number', 'one', 'club', 'hit', 'Yup', 'uh', 'huh', 'But', 'they', 'love', 'it', 'when', 'you', 'make', 'your', 'business', 'public', 'so', 'fuck', 'it', 'Ive', 'got', 'herpes', 'while', 'we', 'on', 'the', 'subject', 'uhhuh', 'And', 'if', 'I', 'told', 'you', 'I', 'had', 'AIDS', 'yall', 'would', 'play', 'it', 'cause', 'you', 'stupid', 'motherfuckers', 'think', 'Im', 'playin', 'when', 'I', 'say', 'it', 'Well', 'I', 'do', 'take', 'pills', 'dont', 'do', 'speed', 'Dont', 'do', 'crack', 'uhuhh', 'dont', 'do', 'coke', 'I', 'do', 'smoke', 'weed', 'uhhuh', 'Dont', 'do', 'smack', 'I', 'do', 'do', 'shrooms', 'do', 'drink', 'beer', 'yup', 'I', 'just', 'wanna', 'make', 'a', 'few', 'things', 'clear', 'My', 'baby', 'mamas', 'not', 'dead', 'uhuhh', 'shes', 'still', 'alive', 'and', 'bitchin', 'yup', 'And', 'I', 'dont', 'have', 'herpes', 'my', 'dicks', 'just', 'itchin', 'Its', 'not', 'syphilis', 'and', 'as', 'for', 'being', 'AIDS', 'infested', 'I', 'dont', 'know', 'yet', 'Im', 'too', 'scared', 'to', 'get', 'tested', 'I', 'got', 'mushrooms', 'I', 'got', 'acid', 'I', 'got', 'tabs', 'and', 'aspirin', 'tablets', 'Im', 'your', 'brother', 'when', 'you', 'need', 'some', 'good', 'weed', 'to', 'set', 'you', 'free', 'You', 'know', 'me', 'Im', 'your', 'friend', 'when', 'you', 'need', 'a', 'minithin', 'Im', 'Slim', 'Shady', 'Im', 'Shady', 'Ha', 'hahha', 'ha', 'Ha', 'hah', 'hah', 'I', 'told', 'you', 'I', 'was', 'Shady', 'Ha', 'hahha', 'hahha', 'Ha', 'hah', 'hahha', 'hahha', 'hahha', 'Yall', 'didnt', 'wanna', 'believe', 'me', 'Im', 'Shady', 'And', 'thats', 'my', 'name']\n"
     ]
    }
   ],
   "source": [
    "text = open('lyrics/eminem.txt', 'rb').read().decode(encoding='utf-8')\n",
    "#text = re.sub('\\n', ' \\n ', text)\n",
    "text = re.sub('\\n', ' ', text)\n",
    "text = re.sub('\\[.*\\]', '', text)\n",
    "words = [word if word == '\\n' else re.sub(r'[^a-zA-Z0-9]', '', word) for word in text.split(' ')]\n",
    "#words = [re.sub(r'[^a-zA-Z0-9]', '', word) for word in text.split(' ')]\n",
    "#print(print(re.findall('\\[.*\\]', text)))\n",
    "words = [word for word in words if word != '']\n",
    "print(f'Length of text: {len(words)} words')\n",
    "\n",
    "vocab = sorted(set(pd.Series(words)))\n",
    "print(f'{len(vocab)} unique words')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = tf.keras.layers.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)\n",
    "    \n",
    "chars_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "\n",
    "def text_from_ids(ids):\n",
    "    l = chars_from_ids(ids).numpy().tolist()\n",
    "    l = [word.decode('utf-8') for word in l]\n",
    "    return ' '.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(words)\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "seq_length = 25\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Look'\n",
      "b'I'\n",
      "b'was'\n",
      "b'gonna'\n",
      "b'go'\n",
      "b'easy'\n",
      "b'on'\n",
      "b'you'\n",
      "b'not'\n",
      "b'to'\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((25,), (25,)), types: (tf.int64, tf.int64)>\n",
      "Input : Look I was gonna go easy on you not to hurt your feelings \n",
      " But Im only going to get this one chance \n",
      " Six\n",
      "Target: I was gonna go easy on you not to hurt your feelings \n",
      " But Im only going to get this one chance \n",
      " Six minutes\n"
     ]
    }
   ],
   "source": [
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example))\n",
    "    print(\"Target:\", text_from_ids(target_example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((128, 25), (128, 25)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 25, 15896) # (batch_size, sequence_length, vocab_size)\n",
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  2034688   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  multiple                  3545088   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  16293400  \n",
      "=================================================================\n",
      "Total params: 21,873,176\n",
      "Trainable params: 21,873,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(25,), dtype=int64, numpy=\n",
       "array([ 3778,  7933,  7933,  8788,  5475, 13153, 15858,  5666,     1,\n",
       "           1,  4434,  8816, 12720, 14595,  9432, 15143, 15474, 10017,\n",
       "        9809,  7527,     1,  3778, 14974, 14546, 15349], dtype=int64)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " So everybody everybody go berzerk shake your body \n",
      " \n",
      " Were gonna rock this house until we knock it down \n",
      " So turn the volume\n",
      "\n",
      "Next Char Predictions:\n",
      " Animal 19th Wasnt doublin Afeni argue leftThe Amityville spot felch Biggie Whos fix believe mount lou amendment snoopin expert lyin misconducts petes Jumbotron bastards glove\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]))\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 7/60 [==>...........................] - ETA: 1:34 - loss: 9.5231"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\matth\\Documents\\codingProjects\\VSCode\\rapbot\\verseGenerator.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/matth/Documents/codingProjects/VSCode/rapbot/verseGenerator.ipynb#ch0000017?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49mEPOCHS, callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rapbot_venv\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/keras/engine/training.py?line=1176'>1177</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/keras/engine/training.py?line=1177'>1178</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/keras/engine/training.py?line=1178'>1179</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/keras/engine/training.py?line=1179'>1180</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/keras/engine/training.py?line=1180'>1181</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/keras/engine/training.py?line=1181'>1182</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/keras/engine/training.py?line=1182'>1183</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/keras/engine/training.py?line=1183'>1184</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/keras/engine/training.py?line=1184'>1185</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/keras/engine/training.py?line=1185'>1186</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rapbot_venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=881'>882</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=883'>884</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=884'>885</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=886'>887</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=887'>888</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rapbot_venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=915'>916</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=918'>919</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=919'>920</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/def_function.py?line=920'>921</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rapbot_venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=3035'>3036</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=3036'>3037</a>\u001b[0m   (graph_function,\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=3037'>3038</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=3038'>3039</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=3039'>3040</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rapbot_venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1958'>1959</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1959'>1960</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1960'>1961</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1961'>1962</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1962'>1963</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1963'>1964</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1964'>1965</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1965'>1966</a>\u001b[0m     args,\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1966'>1967</a>\u001b[0m     possible_gradient_type,\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1967'>1968</a>\u001b[0m     executing_eagerly)\n\u001b[0;32m   <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=1968'>1969</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rapbot_venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=588'>589</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=589'>590</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=590'>591</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=591'>592</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=592'>593</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=593'>594</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=594'>595</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=595'>596</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=596'>597</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=597'>598</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=598'>599</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=599'>600</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=602'>603</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/function.py?line=603'>604</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\rapbot_venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/execute.py?line=57'>58</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/execute.py?line=58'>59</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/execute.py?line=59'>60</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/execute.py?line=60'>61</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     <a href='file:///c%3A/Users/matth/anaconda3/envs/rapbot_venv/lib/site-packages/tensorflow/python/eager/execute.py?line=61'>62</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant([\"Hi, my name is.\"])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "end = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, my name is. \n",
      "mother im in say touch in me \n",
      "rick cause \n",
      "cause off \n",
      "im jewels \n",
      "if cause \n",
      "cause \n",
      "do a club he is \n",
      "he is off \n",
      "\n",
      "me is on \n",
      "soft \n",
      "imma liquor thats \n",
      "in get cant feeling \n",
      "cause is \n",
      "he is off \n",
      "cause is \n",
      "he is but \n",
      "but imma line \n",
      "he thats \n",
      "thats but \n",
      "no line \n",
      "but cant bill is \n",
      "but he is \n",
      "cause mind \n",
      "he set \n",
      "cant is to two \n",
      "thats \n",
      "we is but \n",
      "but he thats \n",
      "and man thats \n",
      "we is \n",
      "but when me \n",
      "but thats \n",
      "but thats \n",
      "thats \n",
      "we is \n",
      "no spray no \n",
      "thats thats \n",
      "thats no \n",
      "thats \n",
      "but thats thats \n",
      "yeah thats \n",
      "youre is \n",
      "raw thats \n",
      "thats thats \n",
      "lookin d \n",
      "thats thats \n",
      "thats thats \n",
      "but rick thats \n",
      "thats thats \n",
      "get get had \n",
      "lets thats \n",
      "thats thats \n",
      "thats thats \n",
      "me is come \n",
      "thats thats \n",
      "thats thats \n",
      "it hard \n",
      "thats thats \n",
      "thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "g thats no \n",
      "thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "it not thats \n",
      "the in speak \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "get dont \n",
      "hard dont \n",
      "yeah set \n",
      "thats thats \n",
      "there \n",
      "thats \n",
      "thats \n",
      "we dont \n",
      "play one \n",
      "thats thats \n",
      "we get thats \n",
      "thats \n",
      "thats \n",
      "thats thats \n",
      "throwin get \n",
      "thats \n",
      "im raps thats \n",
      "hard thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "get thats thats \n",
      "it like thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "get is it \n",
      "hate is thats \n",
      "we is thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "but thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats \n",
      "thats thats \n",
      "me is to \n",
      "thats \n",
      "thats \n",
      "we when thats \n",
      "thats dick \n",
      "\n",
      "i gives yeah \n",
      "you i cant \n",
      "hard is thats \n",
      "\n",
      "bet get get \n",
      "me has thats \n",
      "we thats \n",
      "thats thats \n",
      "thats thats \n",
      "my me is \n",
      "oh get \n",
      "rick thats \n",
      "youre is no back \n",
      "\n",
      "lil cant hard lil is \n",
      "thats play thats thats \n",
      "thats rounds \n",
      "thats thats \n",
      "thats \n",
      "youre thats \n",
      "thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats rounds \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "i play pac thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats \n",
      "it hard thats \n",
      "thats thats \n",
      "thats \n",
      "thats thats \n",
      "it hard thats \n",
      "thats \n",
      "thats thats \n",
      "thats thats \n",
      "me is thats \n",
      "thats thats \n",
      "thats thats \n",
      "\n",
      "we is it wont \n",
      "there is \n",
      "rick thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats it smell \n",
      "play pac thats thats \n",
      "thats \n",
      "thats thats \n",
      "thats shows \n",
      "touch thats \n",
      "whether thats \n",
      "no touch \n",
      "thats no thats \n",
      "thats thats \n",
      "thats \n",
      "it hard dont \n",
      "i dont like \n",
      "thats thats \n",
      "it keep thats \n",
      "thats \n",
      "touch thats \n",
      "some \n",
      "see \n",
      "get cant thats \n",
      "it not today palm \n",
      "he play thats \n",
      "thats thats \n",
      "thats and dont \n",
      "thats thats \n",
      "thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats \n",
      "thats thats \n",
      "it hard level thats \n",
      "this paper thats \n",
      "throwin touch \n",
      "thats paper \n",
      "try set \n",
      "we dont \n",
      "touch thats \n",
      "thats thats thats \n",
      "it thats thats \n",
      "thats \n",
      "paper thats \n",
      "the thats \n",
      "there dont \n",
      "throwin paper thats \n",
      "come is thats \n",
      "try thats thats \n",
      "left thats \n",
      "hard from \n",
      "tell is \n",
      "i play thats \n",
      "it hard dont \n",
      "me is thats \n",
      "thats thats \n",
      "but hard old \n",
      "lil like \n",
      "thats \n",
      "hard thats \n",
      "thats thats \n",
      "thats thats \n",
      "hard dont thats \n",
      "thats \n",
      "if it when play touch \n",
      "it smell thats \n",
      "thats \n",
      "but smell is \n",
      "i touch touch \n",
      "rick but fuck \n",
      "i touch touch \n",
      "thats \n",
      "but touch thats \n",
      "it dont down touch \n",
      "you like gives \n",
      "touch get \n",
      "whether thats \n",
      "raw know from \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "but is it cant \n",
      "double is \n",
      "paper play \n",
      "lil thats \n",
      "come dont \n",
      "hood \n",
      "thats dick \n",
      "i touch off \n",
      "thats thats \n",
      "it hard dont \n",
      "police \n",
      "get is thats \n",
      "thats thats \n",
      "thats thats \n",
      "touch get \n",
      "thats thats \n",
      "i gotta million touch \n",
      "flacko like \n",
      "i gotta touch me \n",
      "thats thats \n",
      "thats bitch \n",
      "me is battle is \n",
      "thats \n",
      "thats thats \n",
      "thats thats \n",
      "i come and \n",
      "i listen thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n",
      "thats thats \n"
     ]
    }
   ],
   "source": [
    "list = [word.numpy().tolist()[0].decode('utf-8') for word in result]\n",
    "for word in list:\n",
    "    if word =='\\n': print()\n",
    "    else: print(word, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(one_step_model, 'one_step')\n",
    "one_step_reloaded = tf.saved_model.load('one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(100):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f0884ffc388fcd56a152c5373099daca06c231f4312f34ab47e55d1081c18afd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('rapbot_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
